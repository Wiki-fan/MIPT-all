\section{семчик}
HDFS 2 PB -- имеем столько места на дисках
Block size 128 mb
avg metadata block 600 B -- метаданные (хранятся только на Namenode) на блок (включая метаданные на реплики)
replication factor=3

Namenode RAM - ?

2 PB/(3*128 MB)*600 B = 3 Гб



Кластер состоит из HDD-дисков. 
R = 130 МБ/сек
seektime = 1 мс
Размер блока - ?, чтобы время на seek составляло 0.1\% времени чтения.

seektime/ 0.0001 = 1000 мс = 1 с.
Размер блока >= 130 МБ.
 


Семинар

\mi{bash}{path#name} позволяет переименовать файл при загрузке

\section{Павел Ахтямов}
Строим частотный словарь слов Википедии. article -> <word> -> (word, 1) -(sort)> (word, <1,...,1>) -add> (word, count) 

Заметка: число мапперов нельзя указать, ибо зависит от разбиения на блоки. Это можно регулировать только глобальными параметрами.

Файл должен быть исполняемым. Для скриптов надо использовать \wikiref{shebang}{Шебанг (Unix)}.

regex101.com

Счётчики в MapReduce. reporter:counter:group,name,number


Семинар
Hive. Люди из Facebook заметили, что типичные задачи работы с хранилищем удобно представлять в чём-то, похожем на реляционную алгебру.

Над кластером строится Hive metastore, в котором хранится информация о таблицах: из каких файлов она состоит, а где они хранятся знает HDFS.
Metastore: table $\rightarrow$ location (папка HDFS) + информация о таблице (колонки, их типы, формат хранения).
То есть, это аналог Namenode. Само оно устроено в виде обычной БД (SQLite, \dots).

Driver Hive: HiveQL $\rightarrow$ MapReduce Jobs.
Преобразуем команду, похожую на обычный SQL-запрос, в каскад MapReduce'ов.


\section{Сем}
ZooKeeper
\begin{enumerate}
	\i PDF
	\i Официальная документация
\end{enumerate}

Основная задача --- средство синхронизации (хотя можно хранить в нём что-то как в ДБ).

Chubby -- система Google для синхронизации хостов. 

Модель данных: древовидная.
Узел может делать \mi{text}{get, get_data, get_children, set_data, create, remove, sync}.

setData(str, version) -- аналогично CAS.

